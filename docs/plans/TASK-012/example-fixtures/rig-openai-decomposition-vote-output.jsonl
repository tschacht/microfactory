# Fixture: rig-openai-decomposition-vote-output.jsonl
# Source: session-52f1d07d-5d2a-40a7-9810-e5898779f287
# Purpose: Captures a rig span around a decomposition vote. The payload embeds
# multiple candidate decompositions and is paired (in the full log) with an
# `API successfully called` event that includes `gen_ai.usage.*` token usage.
# Useful for testing that the `ops` layer can summarize model, provider, op,
# and token counts for each request/response cycle.
{"timestamp":"2025-11-21T18:38:23.244260Z","level":"DEBUG","fields":{"message":"connected to 172.66.0.243:443"},"target":"hyper_util::client::legacy::connect::http","span":{"gen_ai.input.messages":"[{\"role\":\"user\",\"type\":\"message\",\"role\":\"user\",\"content\":[{\"type\":\"input_text\",\"text\":\"You are the decomposition adjudicator. Evaluate the candidate breakdowns below and select the one that yields the safest, most parallelizable execution order.\\n\\nCANDIDATE OPTIONS:\\nOption 1:\\nCreate a minimal Cargo manifest at the repo root (Cargo.toml) with a single-package, edition 2021 configuration and no dependencies.\\nImplement the single-file Rust program at src/main.rs:\\nProvide a tiny helper function: fn greet(name: &amp;str) -&gt; String that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; if the input is blank/whitespace.\\nIn main(), read stdin (one chunk) and print the result of greet(input).\\nAdd unit tests in the same file to exercise the helper:\\nTest greet with a real name (e.g., &quot;Alice&quot; -&gt; &quot;Hello, Alice!&quot;).\\nTest greet with blank/whitespace (e.g., &quot;&quot; and &quot;   &quot; -&gt; &quot;Hello, friend!&quot;).\\nVerify locally by building and testing:\\nRun: cargo test\\nOptional manual run: printf &quot;Alice\\\\n&quot; | cargo run to observe &quot;Hello, Alice!&quot; on stdout.\\n\\nOption 2:\\nCreate or verify a Rust binary project and single source file: run cargo init --bin (or ensure src/main.rs exists in the repo) to establish a single-file executable entry point.\\nImplement a tiny helper and main logic in src/main.rs: add fn greet(name: &amp;str) -&gt; String that trims and substitutes &quot;friend&quot; for blanks, and a main() that reads all stdin, passes to greet, and prints the result with println!.\\nAdd unit tests in the same file: within #[cfg(test)], implement tests for greet(&quot;Alice&quot;) -&gt; &quot;Hello, Alice!&quot; and greet(&quot;  &quot;) -&gt; &quot;Hello, friend!&quot;.\\nRun verification: cargo test (and cargo run to manually test) and ensure the program prints the expected output given stdin.\\n\\nOption 3:\\nInitialize a binary Rust project in the repo: cargo init --bin greeter (creates Cargo.toml and src/main.rs).\\nImplement the single-file greeter in src/main.rs: add a greet(name: &amp;str) -&gt; String function that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; when blank, and a main() that reads all stdin, trims, and prints greet(input).\\nAdd a tiny helper test in the same file: under #[cfg(test)], write tests for greet(&quot;Alice&quot;) and for blank inputs (&quot;&quot; and whitespace) verifying &quot;Hello, Alice!&quot; and &quot;Hello, friend!&quot; respectively.\\nVerify locally: run cargo test to ensure tests pass, then perform manual checks like printf &quot;Alice\\\\n&quot; | cargo run and printf &quot;\\\\n&quot; | cargo run to confirm runtime behavior.\\n\\n\\n\\nRespond with the number of the best option (e.g., `2`).\\n\"}]}]","gen_ai.operation.name":"chat","gen_ai.provider.name":"openai","gen_ai.request.model":"gpt-5-nano","name":"chat"},"spans":[{"gen_ai.input.messages":"[{\"role\":\"user\",\"type\":\"message\",\"role\":\"user\",\"content\":[{\"type\":\"input_text\",\"text\":\"You are the decomposition adjudicator. Evaluate the candidate breakdowns below and select the one that yields the safest, most parallelizable execution order.\\n\\nCANDIDATE OPTIONS:\\nOption 1:\\nCreate a minimal Cargo manifest at the repo root (Cargo.toml) with a single-package, edition 2021 configuration and no dependencies.\\nImplement the single-file Rust program at src/main.rs:\\nProvide a tiny helper function: fn greet(name: &amp;str) -&gt; String that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; if the input is blank/whitespace.\\nIn main(), read stdin (one chunk) and print the result of greet(input).\\nAdd unit tests in the same file to exercise the helper:\\nTest greet with a real name (e.g., &quot;Alice&quot; -&gt; &quot;Hello, Alice!&quot;).\\nTest greet with blank/whitespace (e.g., &quot;&quot; and &quot;   &quot; -&gt; &quot;Hello, friend!&quot;).\\nVerify locally by building and testing:\\nRun: cargo test\\nOptional manual run: printf &quot;Alice\\\\n&quot; | cargo run to observe &quot;Hello, Alice!&quot; on stdout.\\n\\nOption 2:\\nCreate or verify a Rust binary project and single source file: run cargo init --bin (or ensure src/main.rs exists in the repo) to establish a single-file executable entry point.\\nImplement a tiny helper and main logic in src/main.rs: add fn greet(name: &amp;str) -&gt; String that trims and substitutes &quot;friend&quot; for blanks, and a main() that reads all stdin, passes to greet, and prints the result with println!.\\nAdd unit tests in the same file: within #[cfg(test)], implement tests for greet(&quot;Alice&quot;) -&gt; &quot;Hello, Alice!&quot; and greet(&quot;  &quot;) -&gt; &quot;Hello, friend!&quot;.\\nRun verification: cargo test (and cargo run to manually test) and ensure the program prints the expected output given stdin.\\n\\nOption 3:\\nInitialize a binary Rust project in the repo: cargo init --bin greeter (creates Cargo.toml and src/main.rs).\\nImplement the single-file greeter in src/main.rs: add a greet(name: &amp;str) -&gt; String function that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; when blank, and a main() that reads all stdin, trims, and prints greet(input).\\nAdd a tiny helper test in the same file: under #[cfg(test)], write tests for greet(&quot;Alice&quot;) and for blank inputs (&quot;&quot; and whitespace) verifying &quot;Hello, Alice!&quot; and &quot;Hello, friend!&quot; respectively.\\nVerify locally: run cargo test to ensure tests pass, then perform manual checks like printf &quot;Alice\\\\n&quot; | cargo run and printf &quot;\\\\n&quot; | cargo run to confirm runtime behavior.\\n\\n\\n\\nRespond with the number of the best option (e.g., `2`).\\n\"}]}]","gen_ai.operation.name":"chat","gen_ai.provider.name":"openai","gen_ai.request.model":"gpt-5-nano","name":"chat"}]}
{"timestamp":"2025-11-21T18:38:51.153204Z","level":"DEBUG","fields":{"message":"pooling idle connection for (\"https\", api.openai.com)"},"target":"hyper_util::client::legacy::pool"}
{"timestamp":"2025-11-21T18:38:51.154045Z","level":"INFO","fields":{"message":"API successfully called"},"target":"rig::providers::openai::responses_api","span":{"gen_ai.input.messages":"[{\"role\":\"user\",\"type\":\"message\",\"role\":\"user\",\"content\":[{\"type\":\"input_text\",\"text\":\"You are the decomposition adjudicator. Evaluate the candidate breakdowns below and select the one that yields the safest, most parallelizable execution order.\\n\\nCANDIDATE OPTIONS:\\nOption 1:\\nCreate a minimal Cargo manifest at the repo root (Cargo.toml) with a single-package, edition 2021 configuration and no dependencies.\\nImplement the single-file Rust program at src/main.rs:\\nProvide a tiny helper function: fn greet(name: &amp;str) -&gt; String that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; if the input is blank/whitespace.\\nIn main(), read stdin (one chunk) and print the result of greet(input).\\nAdd unit tests in the same file to exercise the helper:\\nTest greet with a real name (e.g., &quot;Alice&quot; -&gt; &quot;Hello, Alice!&quot;).\\nTest greet with blank/whitespace (e.g., &quot;&quot; and &quot;   &quot; -&gt; &quot;Hello, friend!&quot;).\\nVerify locally by building and testing:\\nRun: cargo test\\nOptional manual run: printf &quot;Alice\\\\n&quot; | cargo run to observe &quot;Hello, Alice!&quot; on stdout.\\n\\nOption 2:\\nCreate or verify a Rust binary project and single source file: run cargo init --bin (or ensure src/main.rs exists in the repo) to establish a single-file executable entry point.\\nImplement a tiny helper and main logic in src/main.rs: add fn greet(name: &amp;str) -&gt; String that trims and substitutes &quot;friend&quot; for blanks, and a main() that reads all stdin, passes to greet, and prints the result with println!.\\nAdd unit tests in the same file: within #[cfg(test)], implement tests for greet(&quot;Alice&quot;) -&gt; &quot;Hello, Alice!&quot; and greet(&quot;  &quot;) -&gt; &quot;Hello, friend!&quot;.\\nRun verification: cargo test (and cargo run to manually test) and ensure the program prints the expected output given stdin.\\n\\nOption 3:\\nInitialize a binary Rust project in the repo: cargo init --bin greeter (creates Cargo.toml and src/main.rs).\\nImplement the single-file greeter in src/main.rs: add a greet(name: &amp;str) -&gt; String function that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; when blank, and a main() that reads all stdin, trims, and prints greet(input).\\nAdd a tiny helper test in the same file: under #[cfg(test)], write tests for greet(&quot;Alice&quot;) and for blank inputs (&quot;&quot; and whitespace) verifying &quot;Hello, Alice!&quot; and &quot;Hello, friend!&quot; respectively.\\nVerify locally: run cargo test to ensure tests pass, then perform manual checks like printf &quot;Alice\\\\n&quot; | cargo run and printf &quot;\\\\n&quot; | cargo run to confirm runtime behavior.\\n\\n\\n\\nRespond with the number of the best option (e.g., `2`).\\n\"}]}]","gen_ai.operation.name":"chat","gen_ai.output.messages":"[{\"type\":\"reasoning\",\"id\":\"rs_0f355b937b2eea35006920b19fc9e8819c9042325a7d67c448\",\"summary\":[]},{\"type\":\"message\",\"id\":\"msg_0f355b937b2eea35006920b1baec38819ca5ff381709bd7918\",\"role\":\"assistant\",\"status\":\"completed\",\"content\":[{\"type\":\"output_text\",\"text\":\"3\"}]}]","gen_ai.provider.name":"openai","gen_ai.request.model":"gpt-5-nano","gen_ai.response.id":"resp_0f355b937b2eea35006920b19f8118819c8442faddc0eb4f60","gen_ai.response.model":"gpt-5-nano-2025-08-07","gen_ai.usage.input_tokens":690,"gen_ai.usage.output_tokens":2119,"name":"chat"},"spans":[{"gen_ai.input.messages":"[{\"role\":\"user\",\"type\":\"message\",\"role\":\"user\",\"content\":[{\"type\":\"input_text\",\"text\":\"You are the decomposition adjudicator. Evaluate the candidate breakdowns below and select the one that yields the safest, most parallelizable execution order.\\n\\nCANDIDATE OPTIONS:\\nOption 1:\\nCreate a minimal Cargo manifest at the repo root (Cargo.toml) with a single-package, edition 2021 configuration and no dependencies.\\nImplement the single-file Rust program at src/main.rs:\\nProvide a tiny helper function: fn greet(name: &amp;str) -&gt; String that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; if the input is blank/whitespace.\\nIn main(), read stdin (one chunk) and print the result of greet(input).\\nAdd unit tests in the same file to exercise the helper:\\nTest greet with a real name (e.g., &quot;Alice&quot; -&gt; &quot;Hello, Alice!&quot;).\\nTest greet with blank/whitespace (e.g., &quot;&quot; and &quot;   &quot; -&gt; &quot;Hello, friend!&quot;).\\nVerify locally by building and testing:\\nRun: cargo test\\nOptional manual run: printf &quot;Alice\\\\n&quot; | cargo run to observe &quot;Hello, Alice!&quot; on stdout.\\n\\nOption 2:\\nCreate or verify a Rust binary project and single source file: run cargo init --bin (or ensure src/main.rs exists in the repo) to establish a single-file executable entry point.\\nImplement a tiny helper and main logic in src/main.rs: add fn greet(name: &amp;str) -&gt; String that trims and substitutes &quot;friend&quot; for blanks, and a main() that reads all stdin, passes to greet, and prints the result with println!.\\nAdd unit tests in the same file: within #[cfg(test)], implement tests for greet(&quot;Alice&quot;) -&gt; &quot;Hello, Alice!&quot; and greet(&quot;  &quot;) -&gt; &quot;Hello, friend!&quot;.\\nRun verification: cargo test (and cargo run to manually test) and ensure the program prints the expected output given stdin.\\n\\nOption 3:\\nInitialize a binary Rust project in the repo: cargo init --bin greeter (creates Cargo.toml and src/main.rs).\\nImplement the single-file greeter in src/main.rs: add a greet(name: &amp;str) -&gt; String function that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; when blank, and a main() that reads all stdin, trims, and prints greet(input).\\nAdd a tiny helper test in the same file: under #[cfg(test)], write tests for greet(&quot;Alice&quot;) and for blank inputs (&quot;&quot; and whitespace) verifying &quot;Hello, Alice!&quot; and &quot;Hello, friend!&quot; respectively.\\nVerify locally: run cargo test to ensure tests pass, then perform manual checks like printf &quot;Alice\\\\n&quot; | cargo run and printf &quot;\\\\n&quot; | cargo run to confirm runtime behavior.\\n\\n\\n\\nRespond with the number of the best option (e.g., `2`).\\n\"}]}]","gen_ai.operation.name":"chat","gen_ai.output.messages":"[{\"type\":\"reasoning\",\"id\":\"rs_0f355b937b2eea35006920b19fc9e8819c9042325a7d67c448\",\"summary\":[]},{\"type\":\"message\",\"id\":\"msg_0f355b937b2eea35006920b1baec38819ca5ff381709bd7918\",\"role\":\"assistant\",\"status\":\"completed\",\"content\":[{\"type\":\"output_text\",\"text\":\"3\"}]}]","gen_ai.provider.name":"openai","gen_ai.request.model":"gpt-5-nano","gen_ai.response.id":"resp_0f355b937b2eea35006920b19f8118819c8442faddc0eb4f60","gen_ai.response.model":"gpt-5-nano-2025-08-07","gen_ai.usage.input_tokens":690,"gen_ai.usage.output_tokens":2119,"name":"chat"}]}
{"timestamp":"2025-11-21T18:38:52.091535Z","level":"DEBUG","fields":{"message":"pooling idle connection for (\"https\", api.openai.com)"},"target":"hyper_util::client::legacy::pool"}
{"timestamp":"2025-11-21T18:38:52.092413Z","level":"INFO","fields":{"message":"API successfully called"},"target":"rig::providers::openai::responses_api","span":{"gen_ai.input.messages":"[{\"role\":\"user\",\"type\":\"message\",\"role\":\"user\",\"content\":[{\"type\":\"input_text\",\"text\":\"You are the decomposition adjudicator. Evaluate the candidate breakdowns below and select the one that yields the safest, most parallelizable execution order.\\n\\nCANDIDATE OPTIONS:\\nOption 1:\\nCreate a minimal Cargo manifest at the repo root (Cargo.toml) with a single-package, edition 2021 configuration and no dependencies.\\nImplement the single-file Rust program at src/main.rs:\\nProvide a tiny helper function: fn greet(name: &amp;str) -&gt; String that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; if the input is blank/whitespace.\\nIn main(), read stdin (one chunk) and print the result of greet(input).\\nAdd unit tests in the same file to exercise the helper:\\nTest greet with a real name (e.g., &quot;Alice&quot; -&gt; &quot;Hello, Alice!&quot;).\\nTest greet with blank/whitespace (e.g., &quot;&quot; and &quot;   &quot; -&gt; &quot;Hello, friend!&quot;).\\nVerify locally by building and testing:\\nRun: cargo test\\nOptional manual run: printf &quot;Alice\\\\n&quot; | cargo run to observe &quot;Hello, Alice!&quot; on stdout.\\n\\nOption 2:\\nCreate or verify a Rust binary project and single source file: run cargo init --bin (or ensure src/main.rs exists in the repo) to establish a single-file executable entry point.\\nImplement a tiny helper and main logic in src/main.rs: add fn greet(name: &amp;str) -&gt; String that trims and substitutes &quot;friend&quot; for blanks, and a main() that reads all stdin, passes to greet, and prints the result with println!.\\nAdd unit tests in the same file: within #[cfg(test)], implement tests for greet(&quot;Alice&quot;) -&gt; &quot;Hello, Alice!&quot; and greet(&quot;  &quot;) -&gt; &quot;Hello, friend!&quot;.\\nRun verification: cargo test (and cargo run to manually test) and ensure the program prints the expected output given stdin.\\n\\nOption 3:\\nInitialize a binary Rust project in the repo: cargo init --bin greeter (creates Cargo.toml and src/main.rs).\\nImplement the single-file greeter in src/main.rs: add a greet(name: &amp;str) -&gt; String function that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; when blank, and a main() that reads all stdin, trims, and prints greet(input).\\nAdd a tiny helper test in the same file: under #[cfg(test)], write tests for greet(&quot;Alice&quot;) and for blank inputs (&quot;&quot; and whitespace) verifying &quot;Hello, Alice!&quot; and &quot;Hello, friend!&quot; respectively.\\nVerify locally: run cargo test to ensure tests pass, then perform manual checks like printf &quot;Alice\\\\n&quot; | cargo run and printf &quot;\\\\n&quot; | cargo run to confirm runtime behavior.\\n\\n\\n\\nRespond with the number of the best option (e.g., `2`).\\n\"}]}]","gen_ai.operation.name":"chat","gen_ai.output.messages":"[{\"type\":\"reasoning\",\"id\":\"rs_0bd920c78409955d006920b19ffbd481929299f0c19c58ed80\",\"summary\":[]},{\"type\":\"message\",\"id\":\"msg_0bd920c78409955d006920b1bbea4881928a7f8253cb573eba\",\"role\":\"assistant\",\"status\":\"completed\",\"content\":[{\"type\":\"output_text\",\"text\":\"2\"}]}]","gen_ai.provider.name":"openai","gen_ai.request.model":"gpt-5-nano","gen_ai.response.id":"resp_0bd920c78409955d006920b19f7ba0819280bff1ac8d5b4b44","gen_ai.response.model":"gpt-5-nano-2025-08-07","gen_ai.usage.input_tokens":690,"gen_ai.usage.output_tokens":2695,"name":"chat"},"spans":[{"gen_ai.input.messages":"[{\"role\":\"user\",\"type\":\"message\",\"role\":\"user\",\"content\":[{\"type\":\"input_text\",\"text\":\"You are the decomposition adjudicator. Evaluate the candidate breakdowns below and select the one that yields the safest, most parallelizable execution order.\\n\\nCANDIDATE OPTIONS:\\nOption 1:\\nCreate a minimal Cargo manifest at the repo root (Cargo.toml) with a single-package, edition 2021 configuration and no dependencies.\\nImplement the single-file Rust program at src/main.rs:\\nProvide a tiny helper function: fn greet(name: &amp;str) -&gt; String that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; if the input is blank/whitespace.\\nIn main(), read stdin (one chunk) and print the result of greet(input).\\nAdd unit tests in the same file to exercise the helper:\\nTest greet with a real name (e.g., &quot;Alice&quot; -&gt; &quot;Hello, Alice!&quot;).\\nTest greet with blank/whitespace (e.g., &quot;&quot; and &quot;   &quot; -&gt; &quot;Hello, friend!&quot;).\\nVerify locally by building and testing:\\nRun: cargo test\\nOptional manual run: printf &quot;Alice\\\\n&quot; | cargo run to observe &quot;Hello, Alice!&quot; on stdout.\\n\\nOption 2:\\nCreate or verify a Rust binary project and single source file: run cargo init --bin (or ensure src/main.rs exists in the repo) to establish a single-file executable entry point.\\nImplement a tiny helper and main logic in src/main.rs: add fn greet(name: &amp;str) -&gt; String that trims and substitutes &quot;friend&quot; for blanks, and a main() that reads all stdin, passes to greet, and prints the result with println!.\\nAdd unit tests in the same file: within #[cfg(test)], implement tests for greet(&quot;Alice&quot;) -&gt; &quot;Hello, Alice!&quot; and greet(&quot;  &quot;) -&gt; &quot;Hello, friend!&quot;.\\nRun verification: cargo test (and cargo run to manually test) and ensure the program prints the expected output given stdin.\\n\\nOption 3:\\nInitialize a binary Rust project in the repo: cargo init --bin greeter (creates Cargo.toml and src/main.rs).\\nImplement the single-file greeter in src/main.rs: add a greet(name: &amp;str) -&gt; String function that returns &quot;Hello, &lt;name&gt;!&quot; or &quot;Hello, friend!&quot; when blank, and a main() that reads all stdin, trims, and prints greet(input).\\nAdd a tiny helper test in the same file: under #[cfg(test)], write tests for greet(&quot;Alice&quot;) and for blank inputs (&quot;&quot; and whitespace) verifying &quot;Hello, Alice!&quot; and &quot;Hello, friend!&quot; respectively.\\nVerify locally: run cargo test to ensure tests pass, then perform manual checks like printf &quot;Alice\\\\n&quot; | cargo run and printf &quot;\\\\n&quot; | cargo run to confirm runtime behavior.\\n\\n\\n\\nRespond with the number of the best option (e.g., `2`).\\n\"}]}]","gen_ai.operation.name":"chat","gen_ai.output.messages":"[{\"type\":\"reasoning\",\"id\":\"rs_0bd920c78409955d006920b19ffbd481929299f0c19c58ed80\",\"summary\":[]},{\"type\":\"message\",\"id\":\"msg_0bd920c78409955d006920b1bbea4881928a7f8253cb573eba\",\"role\":\"assistant\",\"status\":\"completed\",\"content\":[{\"type\":\"output_text\",\"text\":\"2\"}]}]","gen_ai.provider.name":"openai","gen_ai.request.model":"gpt-5-nano","gen_ai.response.id":"resp_0bd920c78409955d006920b19f7ba0819280bff1ac8d5b4b44","gen_ai.response.model":"gpt-5-nano-2025-08-07","gen_ai.usage.input_tokens":690,"gen_ai.usage.output_tokens":2695,"name":"chat"}]}
{"timestamp":"2025-11-21T18:38:52.093209Z","level":"DEBUG","fields":{"message":"Decomposition vote completed","step_id":0,"winner_idx":2,"winner_votes":1,"runner_up_votes":1,"vote_k":3},"target":"microfactory::tasks"}
{"timestamp":"2025-11-21T18:38:52.093284Z","level":"INFO","fields":{"message":"Session 52f1d07d-5d2a-40a7-9810-e5898779f287 paused at step 0 (decomposition vote_low_margin) - Vote margin (1) during decomposition vote fell below threshold"},"target":"microfactory"}
{"timestamp":"2025-11-21T18:38:52.094865Z","level":"INFO","fields":{"message":"Use `microfactory resume --session-id 52f1d07d-5d2a-40a7-9810-e5898779f287` after resolving the issue."},"target":"microfactory"}
{"timestamp":"2025-11-21T19:16:34.005564Z","level":"INFO","fields":{"message":"Resuming session 52f1d07d-5d2a-40a7-9810-e5898779f287 previously paused at step 0 (decomposition vote_low_margin) - Vote margin (1) during decomposition vote fell below threshold"},"target":"microfactory"}
